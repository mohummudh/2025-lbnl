{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581a61dd",
   "metadata": {},
   "source": [
    "# Transformers Tutorial: Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2285437c-72ac-42c7-a70e-655b8339ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33ea9e-e41d-4dc8-ae2e-340089f9924e",
   "metadata": {},
   "source": [
    "### Let's open the training and validation files containing examples for top quarks (signal) and QCD jets (background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bbb048-dc2f-4f03-9f02-f3f4e53fb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/global/cfs/cdirs/trn016/transformer'\n",
    "train_data = load_data('top',input_folder,batch=128,dataset_type='train',num_evt = 100_000)\n",
    "val_data = load_data('top',input_folder,batch=128,dataset_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeec21c-cfe9-47e3-9250-e14724fddce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 781 batches of events for training and 3148 for validation\n"
     ]
    }
   ],
   "source": [
    "print (f\"Loading {len(train_data)} batches of events for training and {len(val_data)} for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38a93c-14f3-49ec-90c7-65baeb1a10c8",
   "metadata": {},
   "source": [
    "### We Now need to create a model that will take the data as input and predict a label for each data entry. Let's create a config file with the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62ed545-402a-4b3d-aa49-60c3926efd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_layers': 2,\n",
    "    'hidden_dim': 64,\n",
    "    'activation': nn.ReLU(), #https://docs.pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2a3539-2431-4f5a-8910-f399b4920d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDeepSets(nn.Module):\n",
    "    def __init__(self, input_dim, config, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, config[\"hidden_dim\"])\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(config[\"num_layers\"]):\n",
    "            layers.append(nn.Linear(config[\"hidden_dim\"], config[\"hidden_dim\"]))\n",
    "            layers.append(config[\"activation\"])\n",
    "        self.hidden_layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.output_layer = nn.Linear(config[\"hidden_dim\"], num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        zero_pad_mask = (inputs[:, :, 2] != 0).unsqueeze(-1).float()\n",
    "        x = self.input_layer(inputs) * zero_pad_mask\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x) * zero_pad_mask\n",
    "        x = x.mean(1)  # aggregate over particles\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a778d5c8-5f18-401b-b944-38422d1164ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleDeepSets(input_dim=4,config=config) #remember the inputs are delta eta, delta phi, log(pT), log(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f95bf4-8f95-4742-aa4b-dc6f3e211511",
   "metadata": {},
   "source": [
    "### Now we are going to create the training class that will train the model, but first, let's set up the learning rate and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73397f76-9973-4bad-9bf7-146a01408397",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 5e-4\n",
    "epochs = 100\n",
    "patience = 10 # Number of consecutive epochs to stop the training if the validation loss does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6c7534-3b5f-4d2d-b53c-3f17389a9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = utils.Trainer(train_data,val_data,model,lr,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea3830-5f46-45eb-b27c-0478c17451de",
   "metadata": {},
   "source": [
    "### Let's train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb53f3c-c01d-4d0c-a16f-28fb5704a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.5654, validation loss=0.5278\n",
      "Epoch 2: train loss=0.4296, validation loss=0.3745\n",
      "Epoch 3: train loss=0.3680, validation loss=0.3725\n",
      "Epoch 4: train loss=0.3621, validation loss=0.3590\n",
      "Epoch 5: train loss=0.3584, validation loss=0.3524\n",
      "Epoch 6: train loss=0.3533, validation loss=0.4112\n",
      "Epoch 7: train loss=0.3494, validation loss=0.3438\n",
      "Epoch 8: train loss=0.3460, validation loss=0.3429\n",
      "Epoch 9: train loss=0.3420, validation loss=0.3390\n",
      "Epoch 10: train loss=0.3416, validation loss=0.3400\n",
      "Epoch 11: train loss=0.3405, validation loss=0.3366\n",
      "Epoch 12: train loss=0.3408, validation loss=0.3367\n",
      "Epoch 13: train loss=0.3386, validation loss=0.3366\n",
      "Epoch 14: train loss=0.3382, validation loss=0.3365\n",
      "Epoch 15: train loss=0.3375, validation loss=0.3435\n",
      "Epoch 16: train loss=0.3376, validation loss=0.3353\n",
      "Epoch 17: train loss=0.3372, validation loss=0.3354\n",
      "Epoch 18: train loss=0.3365, validation loss=0.3376\n",
      "Epoch 19: train loss=0.3365, validation loss=0.3348\n",
      "Epoch 20: train loss=0.3365, validation loss=0.3338\n",
      "Epoch 21: train loss=0.3355, validation loss=0.3427\n",
      "Epoch 22: train loss=0.3349, validation loss=0.3343\n",
      "Epoch 23: train loss=0.3350, validation loss=0.3328\n",
      "Epoch 24: train loss=0.3346, validation loss=0.3330\n",
      "Epoch 25: train loss=0.3339, validation loss=0.3336\n",
      "Epoch 26: train loss=0.3348, validation loss=0.3346\n",
      "Epoch 27: train loss=0.3348, validation loss=0.3323\n",
      "Epoch 28: train loss=0.3338, validation loss=0.3329\n",
      "Epoch 29: train loss=0.3342, validation loss=0.3322\n",
      "Epoch 30: train loss=0.3338, validation loss=0.3416\n",
      "Epoch 31: train loss=0.3340, validation loss=0.3359\n",
      "Epoch 32: train loss=0.3335, validation loss=0.3330\n",
      "Epoch 33: train loss=0.3332, validation loss=0.3342\n",
      "Epoch 34: train loss=0.3335, validation loss=0.3331\n",
      "Epoch 35: train loss=0.3330, validation loss=0.3322\n",
      "Epoch 36: train loss=0.3321, validation loss=0.3318\n",
      "Epoch 37: train loss=0.3331, validation loss=0.3311\n",
      "Epoch 38: train loss=0.3321, validation loss=0.3343\n",
      "Epoch 39: train loss=0.3327, validation loss=0.3314\n",
      "Epoch 40: train loss=0.3319, validation loss=0.3317\n",
      "Epoch 41: train loss=0.3325, validation loss=0.3468\n",
      "Epoch 42: train loss=0.3321, validation loss=0.3324\n",
      "Epoch 43: train loss=0.3325, validation loss=0.3336\n",
      "Epoch 44: train loss=0.3319, validation loss=0.3329\n",
      "Epoch 45: train loss=0.3312, validation loss=0.3393\n",
      "Epoch 46: train loss=0.3319, validation loss=0.3315\n",
      "Epoch 47: train loss=0.3317, validation loss=0.3368\n",
      "No improvement for 10 epochs. Early stopping at epoch 47.\n",
      "Training complete. Total time: 681.5s.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc16252-f4ae-4027-88ef-23b258ee0ffd",
   "metadata": {},
   "source": [
    "### Now let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256fe45c-70dc-46b6-a9db-1a8661a8bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('top',input_folder,batch=128,dataset_type='test')\n",
    "predictions, labels = trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6737db7-d095-4762-a2fd-2b38aec08642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9226\n",
      "\n",
      "ACC: 0.8860\n",
      "\n",
      "Signal class 1 vs Background class 0:\n",
      "Class 1 effS at 0.3000534457673921 1.0/effB = 20.925995024875622\n",
      "Class 1 effS at 0.5000890762789869 1.0/effB = 15.16631610576923\n"
     ]
    }
   ],
   "source": [
    "utils.print_metrics(predictions,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf68ae8-ff04-46e5-abbb-5a355a81cd19",
   "metadata": {},
   "source": [
    "### Try changing the hyperparameters, activation functions, layers, learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f5199-b373-4e1b-88cb-66e823f1f076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.6.0",
   "language": "python",
   "name": "pytorch-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
