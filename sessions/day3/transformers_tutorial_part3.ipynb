{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec3808b",
   "metadata": {},
   "source": [
    "# Transformers Tutorial: Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2285437c-72ac-42c7-a70e-655b8339ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "from network import PET2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33ea9e-e41d-4dc8-ae2e-340089f9924e",
   "metadata": {},
   "source": [
    "### Let's open the training and validation files containing examples for top quarks (signal) and QCD jets (background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bbb048-dc2f-4f03-9f02-f3f4e53fb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '/global/cfs/cdirs/trn016/transformer'\n",
    "train_data = load_data('top',input_folder,batch=256,dataset_type='train',num_evt = 100_000)\n",
    "val_data = load_data('top',input_folder,batch=256,dataset_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeec21c-cfe9-47e3-9250-e14724fddce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 390 batches of events for training and 1574 for validation\n"
     ]
    }
   ],
   "source": [
    "print (f\"Loading {len(train_data)} batches of events for training and {len(val_data)} for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38a93c-14f3-49ec-90c7-65baeb1a10c8",
   "metadata": {},
   "source": [
    "### Let's now load the PET Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e40917-b98d-4423-a5fc-1622d8db05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_dim':4,\n",
    "    'hidden_size': 128,\n",
    "    'num_transformers': 8, #number of transformer blocks used\n",
    "    'num_transformers_head':2, #number of transformer blocks used in the task-specific block\n",
    "    'num_heads':8, #number of heads for multi-head attention\n",
    "    'K':10, #number of neighbors considered for the kNN\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a778d5c8-5f18-401b-b944-38422d1164ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PET2(**config) #remember the inputs are delta eta, delta phi, log(pT), log(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f95bf4-8f95-4742-aa4b-dc6f3e211511",
   "metadata": {},
   "source": [
    "### Now we are going to create the training class that will train the model, but first, let's set up the learning rate and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73397f76-9973-4bad-9bf7-146a01408397",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 5e-4\n",
    "epochs = 10\n",
    "patience = 10 # Number of consecutive epochs to stop the training if the validation loss does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6c7534-3b5f-4d2d-b53c-3f17389a9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = utils.Trainer(train_data,val_data,model,lr,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea3830-5f46-45eb-b27c-0478c17451de",
   "metadata": {},
   "source": [
    "### Let's train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb53f3c-c01d-4d0c-a16f-28fb5704a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.2838, validation loss=0.2392\n",
      "Epoch 2: train loss=0.2291, validation loss=0.2176\n",
      "Epoch 3: train loss=0.2098, validation loss=0.1964\n",
      "Epoch 4: train loss=0.1964, validation loss=0.1890\n",
      "Epoch 5: train loss=0.1908, validation loss=0.1853\n",
      "Epoch 6: train loss=0.1857, validation loss=0.1848\n",
      "Epoch 7: train loss=0.1834, validation loss=0.1899\n",
      "Epoch 8: train loss=0.1831, validation loss=0.1856\n",
      "Epoch 9: train loss=0.1797, validation loss=0.1865\n",
      "Epoch 10: train loss=0.1781, validation loss=0.1794\n",
      "Training complete. Total time: 700.1s.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc16252-f4ae-4027-88ef-23b258ee0ffd",
   "metadata": {},
   "source": [
    "### Now let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "256fe45c-70dc-46b6-a9db-1a8661a8bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data('top',input_folder,batch=128,dataset_type='test')\n",
    "predictions, labels = trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6737db7-d095-4762-a2fd-2b38aec08642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9798\n",
      "\n",
      "ACC: 0.9295\n",
      "\n",
      "Signal class 1 vs Background class 0:\n",
      "Class 1 effS at 0.30000989756025137 1.0/effB = 532.712401055409\n",
      "Class 1 effS at 0.500049487801257 1.0/effB = 166.30807248764415\n"
     ]
    }
   ],
   "source": [
    "utils.print_metrics(predictions,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4565450-45ce-4b2e-b5ec-0fb605a44fc3",
   "metadata": {},
   "source": [
    "### Now let's load the pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23758746-b7a2-4ee0-97e0-1c27fb471ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping MPFourier.freqs: shape mismatch (checkpoint: torch.Size([128]), model: missing)\n",
      "Skipping MPFourier.phases: shape mismatch (checkpoint: torch.Size([128]), model: missing)\n",
      "Skipping time_embed.fc1.weight: shape mismatch (checkpoint: torch.Size([256, 128]), model: missing)\n",
      "Skipping time_embed.fc2.weight: shape mismatch (checkpoint: torch.Size([128, 256]), model: missing)\n",
      "Skipping time_embed.norm.alpha: shape mismatch (checkpoint: torch.Size([1]), model: missing)\n",
      "Skipping time_embed.norm.weight: shape mismatch (checkpoint: torch.Size([256]), model: missing)\n",
      "Skipping add_embed.0.fc1.weight: shape mismatch (checkpoint: torch.Size([256, 4]), model: missing)\n",
      "Skipping add_embed.0.fc2.weight: shape mismatch (checkpoint: torch.Size([128, 256]), model: missing)\n",
      "Skipping add_embed.0.norm.alpha: shape mismatch (checkpoint: torch.Size([1]), model: missing)\n",
      "Skipping add_embed.0.norm.weight: shape mismatch (checkpoint: torch.Size([256]), model: missing)\n",
      "Skipping pid_embed.0.weight: shape mismatch (checkpoint: torch.Size([9, 128]), model: missing)\n",
      "Skipping out.weight: explicitly excluded from loading\n",
      "Skipping out.bias: explicitly excluded from loading\n"
     ]
    }
   ],
   "source": [
    "utils.restore_checkpoint(model,input_folder,'best_model_pretrain_s.pt')\n",
    "#These messages are all fine and related to model layers that are not relevant for classiciation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eef8519-4b95-486a-9bbd-ec1baafcda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 5e-5 #Notice the learning rate is much smaller than before\n",
    "epochs = 10\n",
    "patience = 10 # Number of consecutive epochs to stop the training if the validation loss does not improve\n",
    "trainer = utils.Trainer(train_data,val_data,model,lr,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1fe0bae-7429-4398-ace5-db793e47c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.1902, validation loss=0.1661\n",
      "Epoch 2: train loss=0.1626, validation loss=0.1645\n",
      "Epoch 3: train loss=0.1587, validation loss=0.1676\n",
      "Epoch 4: train loss=0.1544, validation loss=0.1635\n",
      "Epoch 5: train loss=0.1501, validation loss=0.1655\n",
      "Epoch 6: train loss=0.1464, validation loss=0.1637\n",
      "Epoch 7: train loss=0.1418, validation loss=0.1675\n",
      "Epoch 8: train loss=0.1369, validation loss=0.1691\n",
      "Epoch 9: train loss=0.1298, validation loss=0.1751\n",
      "Epoch 10: train loss=0.1220, validation loss=0.1823\n",
      "Training complete. Total time: 706.3s.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae92964-a2fe-4805-a113-d9948c9cf2f2",
   "metadata": {},
   "source": [
    "### Because the pre-trained model already starts from useful weights, they are quicker to overtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3f5ed7-2f4b-478f-be48-ac20e8cb375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels = trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c509579-16cb-4d7d-ab3b-aacaccc69082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9834\n",
      "\n",
      "ACC: 0.9354\n",
      "\n",
      "Signal class 1 vs Background class 0:\n",
      "Class 1 effS at 0.3000148463403771 1.0/effB = 1030.091836734694\n",
      "Class 1 effS at 0.50003464146088 1.0/effB = 275.0653950953678\n"
     ]
    }
   ],
   "source": [
    "utils.print_metrics(predictions,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c1c41-0f8f-4fdf-897f-81f4ed0da18d",
   "metadata": {},
   "source": [
    "### Try changing the hyperparameters of the model to see if you can improve the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.6.0",
   "language": "python",
   "name": "pytorch-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
